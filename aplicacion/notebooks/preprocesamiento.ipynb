{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5TEKEMyNERD"
   },
   "source": [
    "# Análisis de Sentimientos a Nivel de Texto: Preprocesamiento de los Datos\n",
    "---\n",
    "\n",
    "> **Proyecto final de Asignatura Sistemas Computacionales <br>\n",
    "Escuela de Ingeniería de Sistemas <br>\n",
    "Universidad de Los Andes <br>\n",
    "Autor: Jhonathan Abreu <br>**\n",
    "\n",
    "---\n",
    "<br>\n",
    "La función de este notebook es describir las primeras etapas del procesamiento de la data que alimentará el modelo de clasificación para el análisis de sentimientos. En este caso, se tomarán los datos del [formulario](https://docs.google.com/forms/d/e/1FAIpQLSdugT3KgsfQEmvB0XVnWhP3Cd5t1fSSJ7mqBY2-I_IZyxBYew/viewform?usp=sf_link) de Google Forms utilizado para la recolección de datos. El resultado final será un archivo CSV con todas las frases y su respectivas etiquetas (positivo, negativo, neutral).\n",
    "\n",
    "## Bibliotecas y módulos necesarios para el proyecto\n",
    "---\n",
    "\n",
    "Este y los demás notebooks están implementados para ser ejecutados con `Python 3`. Se deben instalar los siguientes módulos de para la ejecución de este y los demás notebooks correspondientes al presente proyecto:\n",
    "\n",
    "*  Pandas (v0.22.0)\n",
    "*  Numpy (v1.14.5)\n",
    "*  NLTK (v3.2.5)\n",
    "*  sklearn (scikit-learn, v0.19.1)\n",
    "*  Keras (v2.1.6)\n",
    "*  TensorFlow (opcional, si la instalación de Keras lo requiere, v1.9.0rc0)\n",
    "*  matplotlib (v2.1.2)\n",
    "*  seaborn (v0.7.1)\n",
    "\n",
    "Por lo general, los módulos Pandas, Numpy, sklearn, matplotlib y seaborn son distribuídos con [Anaconda](https://anaconda.org/anaconda/python), el cual también provee una distribución del paquete `jupyter-lab`, el cual permite visualizar y editar notebooks de Python. Las versiones mostradas son las instaladas en Colaboratory, con un entorno de Python 3. Se recomienda utilizar Colaboratory o, en caso de usar un entorno local, instalar Anaconda y los paquetes que sean necesarios (principalmente TensorFlow, Keras y NLTK).\n",
    "\n",
    "## Base de datos\n",
    "---\n",
    "\n",
    "Los datos a ser utilizados para el entrenamiento y prueba del clasificador se encuentran alojados en Google Drive y pueden descargarse en el siguiente enlace:\n",
    "\n",
    "> [Datos de entrenamiento](https://drive.google.com/file/d/1CoaP5GcoVilWu1hYansyO06pvKCb1Ia8/view?usp=sharing)\n",
    "\n",
    "## Configuración del sistemas de archivos de Google Drive\n",
    "---\n",
    "\n",
    "Este proyecto está diseñado para ser poder ser ejecutado en un entorno con Python 3 en Google Colaboratory, por lo cual, los datasets deben estar ubicados en un directorio de su Drive. A continuación, se muestra la configuración del sistema de archivos. Si desea utilizar Colaboratory, ejecute la siguiente celda de código para configurar el sistema de archivos de su Drive.\n",
    "\n",
    "> **Nota 1**: durante la configuración, se le va a solicitar dos (2) veces abrir un enlace, inicicar sesión con su cuenta de Google y copiar y pegar un token de autenticación.\n",
    "\n",
    "> **Nota 2**: específicamente, el arbol de directorios que se muestra en el bloque de declaración de constantes, debe replicarse para el correcto funcionamiento de estos notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32146,
     "status": "ok",
     "timestamp": 1529262303336,
     "user": {
      "displayName": "Jhonathan Abreu",
      "photoUrl": "//lh4.googleusercontent.com/-4bMUXodd-B0/AAAAAAAAAAI/AAAAAAAAAlY/Lc07exuN7Aw/s50-c-k-no/photo.jpg",
      "userId": "117165292541590122752"
     },
     "user_tz": 240
    },
    "id": "KW0QR7i8M8sT",
    "outputId": "f274cffb-a2d8-4102-9598-353c649a2007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpg: keybox '/tmp/tmps9mbp_uy/pubring.gpg' created\n",
      "gpg: /tmp/tmps9mbp_uy/trustdb.gpg: trustdb created\n",
      "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
      "gpg: Total number processed: 1\n",
      "gpg:               imported: 1\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "··········\n",
      "/bin/sh: 1: sshfs: not found\n",
      "Archivos en Drive:\n",
      "aplicacion.ipynb  mejormodelo.ipynb  modelos\n",
      "datasets\t  modelo.ipynb\t     preprocesamiento.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Instalar la biblioteca FUSE (Filesystem in Userspase) para manejar el sistema\n",
    "# de archivos de Google Drive\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get install -y -qq software-properties-common python-software-properties \\\n",
    "    module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Importar bibliotecas necesarias para autenticación\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import getpass\n",
    "\n",
    "# Generar los tokens de autorización para Colaboratory\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Generar credenciales para la biblioteca FUSE\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "\n",
    "!google-drive-ocamlfuse -headless -id={credentials.client_id} \\\n",
    "    -secret={credentials.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={credentials.client_id} \\\n",
    "    -secret={credentials.client_secret}\n",
    "\n",
    "# Montar sistema de archivos\n",
    "!fusermount -u drive\n",
    "!sshfs -u drive\n",
    "\n",
    "# Crear un directorio y montar Google Drive usando ese directorio\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "# Prueba: mostrar contenido de un directorio en drive\n",
    "print ('Archivos en Drive:')\n",
    "!ls drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaración de constantes\n",
    "---\n",
    "\n",
    "Las siguientes constantes son necesarias para ubicar los datasets y los modelos. Modifique según sea necesario, si va a utilizar Colaboratory o un entorno local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GxOtcQwcSbJT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directorios de los datasets\n",
    "\n",
    "#   NOTA: cambiar PROJECT_DIR al directorio raíz del proyecto\n",
    "#     Para drive, cambie la siguiente variable a la ruta del\n",
    "#     proyecto en su Drive:\n",
    "#PROJECT_DIR = 'drive/ULA/sistemascomputacionales/aplicacion'\n",
    "#     Para entorno local, cambie la siguiente variable para apunta\n",
    "#     a la ruta abosluta del proyecto en su disco:\n",
    "PROJECT_DIR = ('/home/jhonathanabreu/Documentos/ula/sistemas_computacionales/'\n",
    "               'Proyecto_SistemasComputacionales_AbreuJ/aplicacion')\n",
    "DATASETS_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
    "ORIGINAL_DATASETS_DIR = os.path.join(DATASETS_DIR, 'originales')\n",
    "PROCESSED_DATASETS_DIR = os.path.join(DATASETS_DIR, 'procesados')\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, 'modelos')\n",
    "\n",
    "# Etiquetas de los sentimientos\n",
    "POSITIVE_SENTIMENT_LABEL = 'positivo'\n",
    "NEGATIVE_SENTIMENT_LABEL = 'negativo'\n",
    "NEUTRAL_SENTIMENT_LABEL = 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_KG2FeSR-dh"
   },
   "source": [
    "## Preprocesamiento de los datos\n",
    "---\n",
    "\n",
    "El procesamiento inicial de los datos es sencillo y consiste únicamente en:\n",
    "\n",
    "1.   Obtener las oraciones del archivo CSV generado por el formulario\n",
    "2.   Etiquetar cada oración según la columna a la que pertenece:\n",
    "     *   Columna 4: oraciones positivas\n",
    "     *   Columna 5:oraciones negativas\n",
    "     *   Columna 6: oraciones neutrales\n",
    "3.   Escribir las oraciones con sus etiquetas en un archivo CSV de salida.\n",
    "\n",
    "<br>\n",
    "### Preprocesamiento de los datos del formulario\n",
    "\n",
    "Esta es la etapa final del preprocesamiento del formulario, en la cual se produce el archivo CSV con los datos preparados para ser alimentados al clasificador.\n",
    "\n",
    "La siguiente función se encarga de realizar lo anterior mencionado:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4285,
     "status": "ok",
     "timestamp": 1529262342376,
     "user": {
      "displayName": "Jhonathan Abreu",
      "photoUrl": "//lh4.googleusercontent.com/-4bMUXodd-B0/AAAAAAAAAAI/AAAAAAAAAlY/Lc07exuN7Aw/s50-c-k-no/photo.jpg",
      "userId": "117165292541590122752"
     },
     "user_tz": 240
    },
    "id": "mh2k2YAqhv2S",
    "outputId": "822fa8ec-8870-422f-dff9-9ac148ed359d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_data.csv\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Función de carga de los datos del formulario de Google Forms.\n",
    "#\n",
    "# Parámetros:\n",
    "#    inputFileName: ruta del archivo CSV del formulario.\n",
    "#    outputFileName: ruta del archivo CSV para escribir las oraciones\n",
    "#                    etiquetadas.\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def getDataFromForm(inputFileName, outputFileName):\n",
    "    # En las columnas 5, 6 y 7 se encuentran las frases positiva, negativa y\n",
    "    # neutral, respectivamente.\n",
    "    possitiveSentimentRow = 4\n",
    "    negativeSentimentRow = 5\n",
    "    neutralSentimentRow = 6\n",
    "    \n",
    "    sentences = {\n",
    "        'sentence': [],\n",
    "        'sentiment': []\n",
    "    }\n",
    "    \n",
    "    with open(inputFileName, newline = '') as formDataFile:\n",
    "        with open(outputFileName, 'w') as labeledDataFile:\n",
    "            # Lector del archivo original\n",
    "            csvReader = csv.reader(formDataFile)\n",
    "            # Escritor del archivo de data etiquetada\n",
    "            csvWriter = csv.writer(labeledDataFile)\n",
    "            \n",
    "            csvReader.__next__()  # Saltar el header\n",
    "            \n",
    "            for row in csvReader:\n",
    "                # Se escriben las oraciones en las columnas 4, 5 y 6\n",
    "                # con las etiquetas positivo, negativo y neutral,\n",
    "                # respectivamente.\n",
    "                csvWriter.writerow([row[possitiveSentimentRow],\n",
    "                                    POSITIVE_SENTIMENT_LABEL])\n",
    "                csvWriter.writerow([row[negativeSentimentRow],\n",
    "                                    NEGATIVE_SENTIMENT_LABEL])\n",
    "                csvWriter.writerow([row[neutralSentimentRow],\n",
    "                                    NEUTRAL_SENTIMENT_LABEL])\n",
    "\n",
    "formDataFile = os.path.join(ORIGINAL_DATASETS_DIR, 'dataset.csv')\n",
    "labeledDataFile = os.path.join(PROCESSED_DATASETS_DIR, 'labeled_data.csv')\n",
    "\n",
    "getDataFromForm(formDataFile, labeledDataFile)\n",
    "\n",
    "!ls {PROCESSED_DATASETS_DIR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JuHnoUAOyiH6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "preprocesamiento.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
