{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w0hFHaehVUqx"
   },
   "source": [
    "# Análisis de Sentimientos a Nivel de Texto: Aplicación Final\n",
    "---\n",
    "\n",
    "> **Proyecto final de Asignatura Sistemas Computacionales <br>\n",
    "Escuela de Ingeniería de Sistemas <br>\n",
    "Universidad de Los Andes <br>\n",
    "Autor: Jhonathan Abreu <br>**\n",
    "\n",
    "---\n",
    "<br>\n",
    "La función de este notebook es la presentación de una aplicación que muestre la utilización del modelo generado en el notebook `modelo.ipynb`. Con esto se pretente probar el clasificador, al predecir el sentimiento de un conjunto de oraciones distintas a las que se utilizaron para el entrenamiento y prueba del modelo.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Configuración del sistema de archivos de Google Drive\n",
    "---\n",
    "\n",
    "En primer lugar, se debe configurar el sistema de archivos de Google Drive, si va a utilizar Colaboratory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51409,
     "status": "ok",
     "timestamp": 1529255121717,
     "user": {
      "displayName": "Jhonathan Abreu",
      "photoUrl": "//lh4.googleusercontent.com/-4bMUXodd-B0/AAAAAAAAAAI/AAAAAAAAAlY/Lc07exuN7Aw/s50-c-k-no/photo.jpg",
      "userId": "117165292541590122752"
     },
     "user_tz": 240
    },
    "id": "oxPqq28ksnSz",
    "outputId": "169618ce-2267-486e-fa82-f8bbdef88502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpg: keybox '/tmp/tmpacny_y2v/pubring.gpg' created\n",
      "gpg: /tmp/tmpacny_y2v/trustdb.gpg: trustdb created\n",
      "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
      "gpg: Total number processed: 1\n",
      "gpg:               imported: 1\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "··········\n",
      "/bin/sh: 1: sshfs: not found\n",
      "Archivos en Drive:\n",
      "aplicacion.ipynb  mejormodelo.ipynb  modelos\n",
      "datasets\t  modelo.ipynb\t     preprocesamiento.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Instalar la biblioteca FUSE (Filesystem in Userspase) para manejar el sistema\n",
    "# de archivos de Google Drive\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get install -y -qq software-properties-common python-software-properties \\\n",
    "    module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Importar bibliotecas necesarias para autenticación\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import getpass\n",
    "\n",
    "# Generar los tokens de autorización para Colaboratory\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Generar credenciales para la biblioteca FUSE\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "\n",
    "!google-drive-ocamlfuse -headless -id={credentials.client_id} \\\n",
    "    -secret={credentials.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={credentials.client_id} \\\n",
    "    -secret={credentials.client_secret}\n",
    "\n",
    "# Montar sistema de archivos\n",
    "!fusermount -u drive\n",
    "!sshfs -u drive\n",
    "\n",
    "# Crear un directorio y montar Google Drive usando ese directorio\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "# Prueba: mostrar contenido de un directorio en drive\n",
    "print ('Archivos en Drive:')\n",
    "!ls drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qiBjLiasopB"
   },
   "source": [
    "<br>\n",
    "\n",
    "## Declaración de constantes\n",
    "---\n",
    "\n",
    "Las siguientes constantes son necesarias para ubicar los datasets y los modelos. Modifique según sea necesario, si va a utilizar Colaboratory o un entorno local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MrYGpgrOVNDF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directorios de los datasets\n",
    "\n",
    "#   NOTA: cambiar PROJECT_DIR al directorio raíz del proyecto\n",
    "#     Para drive, cambie la siguiente variable a la ruta del\n",
    "#     proyecto en su Drive:\n",
    "#PROJECT_DIR = 'drive/ULA/sistemascomputacionales/aplicacion'\n",
    "#     Para entorno local, cambie la siguiente variable para apunta\n",
    "#     a la ruta abosluta del proyecto en su disco:\n",
    "PROJECT_DIR = ('/home/jhonathanabreu/Documentos/ula/sistemas_computacionales/'\n",
    "               'Proyecto_SistemasComputacionales_AbreuJ/aplicacion')\n",
    "DATASETS_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
    "ORIGINAL_DATASETS_DIR = os.path.join(DATASETS_DIR, 'originales')\n",
    "PROCESSED_DATASETS_DIR = os.path.join(DATASETS_DIR, 'procesados')\n",
    "EVALUATION_DATASETS_DIR = os.path.join(DATASETS_DIR, 'evaluacion')\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, 'modelos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPBsp6tvqoUj"
   },
   "source": [
    "<br>\n",
    "## Preparación del entorno y funciones para el vectorizador\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2075,
     "status": "ok",
     "timestamp": 1529255128699,
     "user": {
      "displayName": "Jhonathan Abreu",
      "photoUrl": "//lh4.googleusercontent.com/-4bMUXodd-B0/AAAAAAAAAAI/AAAAAAAAAlY/Lc07exuN7Aw/s50-c-k-no/photo.jpg",
      "userId": "117165292541590122752"
     },
     "user_tz": 240
    },
    "id": "FbDZYLwcqtra",
    "outputId": "58136946-ed95-491c-b040-1f96b7899226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jhonathanabreu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jhonathanabreu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# Descarga y carga de la lista de palabras vacías de NLTK\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "spanishStopWords = stopwords.words('spanish')\n",
    "\n",
    "# Carga y extensión de la lista de signos de puntuación y otros símbolos.\n",
    "\n",
    "nonWords = list(punctuation)\n",
    "nonWords.extend(['¿', '¡'])  # Se agregan estos símbolos (español)\n",
    "nonWords.extend(map(str,range(10)))  # Se agregan los dígitos numéricos\n",
    "\n",
    "# Stemmer, objeto que llevará las palabras a sus raíces \n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# Función que aplica el stemming\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmedTokens = []\n",
    "    for token in tokens:\n",
    "        stemmedTokens.append(stemmer.stem(token))\n",
    "        \n",
    "    return stemmedTokens\n",
    "\n",
    "# Función que limpia y tokeniza las frases\n",
    "def tokenize(text):\n",
    "    # Eliminación de símbolos y números\n",
    "    text = ''.join([c for c in text if c not in nonWords])\n",
    "    # Tokeninazión\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # Stemming\n",
    "    try:\n",
    "        stemmedTokens = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stemmedTokens = ['']\n",
    "        \n",
    "    return stemmedTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eiGpBL5tU01"
   },
   "source": [
    "<br>\n",
    "## Predictor de Sentimientos\n",
    "---\n",
    "\n",
    "### Carga del vectorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bKIFrRppsO1O"
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "def loadVectorizer(self, vectorizerFileName):\n",
    "    vectorizer = joblib.load(vectorizerFileName)\n",
    "    \n",
    "    # Cálculo de la dimensión de los vectores\n",
    "    sentence = 'Test sentence for calculating vectors dimension'\n",
    "    sentenceVector = vectorizer.transform([sentence])\n",
    "    \n",
    "    self.vectorsDimension = sentenceVector.shape[1]\n",
    "    \n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55M-dDUlwnEU"
   },
   "source": [
    "### Carga del clasificador\n",
    "\n",
    "Primero, vamos a **definir el modelo** como en el notebook `modelo.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1529255145854,
     "user": {
      "displayName": "Jhonathan Abreu",
      "photoUrl": "//lh4.googleusercontent.com/-4bMUXodd-B0/AAAAAAAAAAI/AAAAAAAAAlY/Lc07exuN7Aw/s50-c-k-no/photo.jpg",
      "userId": "117165292541590122752"
     },
     "user_tz": 240
    },
    "id": "Ft_Zx9I_w3oy",
    "outputId": "4e97227d-2c2f-4357-a8f6-2d82ca6c4d43"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "def buildModel(self, inputDimension):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(128, 1, input_shape = (1, inputDimension),\n",
    "                     activation = 'relu'))\n",
    "    model.add(Conv1D(32, 1, activation = 'relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))    \n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nebKRsRKxDLQ"
   },
   "source": [
    "<br>\n",
    "El siguiente paso es la **carga del modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SisPdRi_xH_4"
   },
   "outputs": [],
   "source": [
    "def loadClassifier(self, classifierFileName):\n",
    "    model = self.buildModel(self.vectorsDimension)\n",
    "    model.load_weights(classifierFileName)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_S8biIGz4b-"
   },
   "source": [
    "### Preparación de la data de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-97OAkhLz37m"
   },
   "outputs": [],
   "source": [
    "def prepareInput(self, inputData):\n",
    "    vectors = self.vectorizer.transform(inputData).toarray()\n",
    "    vectors = vectors.reshape(vectors.shape[0], 1, vectors.shape[1])\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viRu891zfzu8"
   },
   "source": [
    "### Predición (clasificación) de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FzpyEP0Ff3p7"
   },
   "outputs": [],
   "source": [
    "def predict(self, sentences):\n",
    "    if isinstance(sentences, str):\n",
    "        sentences = [sentences]\n",
    "    else:\n",
    "        try:\n",
    "           _ = (e for e in sentences)\n",
    "        except TypeError:\n",
    "            # No es un iterable\n",
    "            return None\n",
    "        \n",
    "    vectors = self.prepareInput(sentences)\n",
    "    \n",
    "    probabilities = self.classifier.predict(vectors)\n",
    "    sentiments = [self.sentimentLabels[np.argmax(sentimentProbabilities)]\n",
    "                  for sentimentProbabilities in probabilities]\n",
    "    \n",
    "    dataFrameItems = [('Oración', sentences),\n",
    "                      ('Sentimiento', sentiments)]\n",
    "    \n",
    "    return pd.DataFrame.from_items(dataFrameItems)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSHA2DPsOSeM"
   },
   "source": [
    "### La clase final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K9X0nwP5OXCN"
   },
   "outputs": [],
   "source": [
    "class SentimentPredictor:\n",
    "    \n",
    "    sentimentLabels = {\n",
    "        0: 'Negativo',\n",
    "        1: 'Neutral',\n",
    "        2: 'Positivo'\n",
    "    }\n",
    "    \n",
    "    vectorsDimension = 0\n",
    "    \n",
    "    def __init__(self, vectorizerFilename, classifierFilename):\n",
    "        self.vectorizerFilename = vectorizerFilename\n",
    "        self.classifierFilename = classifierFilename\n",
    "        \n",
    "        # Carga del vectorizador\n",
    "        self.vectorizer = self.loadVectorizer(self.vectorizerFilename)\n",
    "        \n",
    "        # Carga del clasificador\n",
    "        self.classifier = self.loadClassifier(self.classifierFilename)\n",
    "        \n",
    "        \n",
    "    # Métodos de la clase\n",
    "    \n",
    "    loadVectorizer = loadVectorizer\n",
    "    \n",
    "    buildModel = buildModel\n",
    "    \n",
    "    loadClassifier = loadClassifier\n",
    "    \n",
    "    prepareInput = prepareInput\n",
    "    \n",
    "    predict = predict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-86NFavJpamo"
   },
   "source": [
    "<br>\n",
    "## Clasificando oraciones\n",
    "---\n",
    "\n",
    "### Carga e inicialización del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Gngz_iYPptg6"
   },
   "outputs": [],
   "source": [
    "vectorizerFilename = os.path.join(MODELS_DIR, 'vectorizador.pkl')\n",
    "classifierFilename = os.path.join(MODELS_DIR, 'modelo.hdf5')\n",
    "\n",
    "classifier = SentimentPredictor(vectorizerFilename, classifierFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedicción\n",
    "\n",
    "El archivo `oraciones.txt` contiene algunas frase para probar. Añada oraciones, una en cada línea, si desea probar otras diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6_H_q3EVkYY4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oración</th>\n",
       "      <th>Sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoy será un gran día pues voy a alcanzar todas mis metas</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Que terrible es la comida que preparas</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Todos tus sueños se volverán realidad, solo ten fe en ti mismo</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mejor temprano que tarde, mejor tarde que nunca</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eres la mejor persona del mundo mundial</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soy una persona muy inutil</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tengo mucha hambre y sueño</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No tengo nada que decir</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eres una persona terriblemente malvada y mala</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tu trabajo no sirve y es malo</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gracias a todos por los mensajes!!!!</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hermoso</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asco, mal, malvado, dificil</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Oración Sentimiento\n",
       "0   Hoy será un gran día pues voy a alcanzar todas mis metas        Positivo  \n",
       "1   Que terrible es la comida que preparas                          Neutral   \n",
       "2   Todos tus sueños se volverán realidad, solo ten fe en ti mismo  Positivo  \n",
       "3   Mejor temprano que tarde, mejor tarde que nunca                 Positivo  \n",
       "4   Eres la mejor persona del mundo mundial                         Positivo  \n",
       "5   Soy una persona muy inutil                                      Negativo  \n",
       "6   Tengo mucha hambre y sueño                                      Positivo  \n",
       "7   No tengo nada que decir                                         Neutral   \n",
       "8   Eres una persona terriblemente malvada y mala                   Negativo  \n",
       "9   Tu trabajo no sirve y es malo                                   Negativo  \n",
       "10  Gracias a todos por los mensajes!!!!                            Neutral   \n",
       "11  hermoso                                                         Positivo  \n",
       "12  asco, mal, malvado, dificil                                     Negativo  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentencesFilename = os.path.join(EVALUATION_DATASETS_DIR, 'oraciones.txt')\n",
    "with open(sentencesFilename) as file:\n",
    "    sentences = file.read().splitlines()\n",
    "\n",
    "predictions = classifier.predict(sentences)\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a6Ei0TYZpqdg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "aplicacion.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
